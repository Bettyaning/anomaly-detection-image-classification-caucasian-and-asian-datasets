MAKE SURE TO CHANGE FILE PATHS FOR DATASETS!!
The presence of bias within facial recognition systems has raised concerns about fairness and accuracy in automated decision-making processes. This study investigates bias present in Asian and Caucasian datasets. Using custom and pre-trained convolutional neural network (CNN) models, facial images were classified based on ethnicity. The hypothesis that there would be more anomalies in the Asian dataset than the Caucasian dataset was partially supported by the findings. While disparities in classification performance and clustering outcomes between the two datasets were observed, the difference in anomalies was not substantial, indicating biases may exist in both datasets to varying degrees. Future research directions include exploring larger and more diverse datasets, investigating the impact of demographic factors, and incorporating advanced machine learning techniques to mitigate biases. Ethical considerations such as privacy, consent and accountability are paramount, emphasising the need for responsible deployment of facial recognition technology. Continued research efforts are crucial to advancing our understanding of biases in facial recognition systems and fostering the development of more inclusive technology for societal benefit.![image](https://github.com/Bettyaning/anomaly-detection-image-classification-caucasian-and-asian-datasets/assets/101409299/db0d9111-13cb-4e6c-8897-a4f68f750b80)
